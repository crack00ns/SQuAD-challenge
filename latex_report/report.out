\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.2}{Model}{}% 2
\BOOKMARK [2][-]{subsection.2.1}{Word and Character Embedding Layer}{section.2}% 3
\BOOKMARK [2][-]{subsection.2.2}{Context and Question Encoding Layer}{section.2}% 4
\BOOKMARK [2][-]{subsection.2.3}{Attention Layer}{section.2}% 5
\BOOKMARK [3][-]{subsubsection.2.3.1}{Bidirectional attention flow}{subsection.2.3}% 6
\BOOKMARK [3][-]{subsubsection.2.3.2}{Dynamic Co-Attention}{subsection.2.3}% 7
\BOOKMARK [3][-]{subsubsection.2.3.3}{Hybrid BiDAF-Co-Attention \(New Model\)}{subsection.2.3}% 8
\BOOKMARK [3][-]{subsubsection.2.3.4}{Double Cross Attention \(New Model\)}{subsection.2.3}% 9
\BOOKMARK [1][-]{section.3}{Experiments}{}% 10
\BOOKMARK [2][-]{subsection.3.1}{Results}{section.3}% 11
\BOOKMARK [2][-]{subsection.3.2}{Hyperparameter Tuning}{section.3}% 12
\BOOKMARK [2][-]{subsection.3.3}{Error Analysis}{section.3}% 13
\BOOKMARK [1][-]{section.4}{Conclusions and Future work}{}% 14
